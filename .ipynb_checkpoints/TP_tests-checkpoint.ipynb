{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "63f3cc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.ml.stat import Correlation\n",
    "from pyspark.ml.feature import PCA, PCAModel\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from pyspark.ml.classification import LogisticRegression, LogisticRegressionModel\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "import time\n",
    "from os.path import isdir\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "dc231cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assemble_features(dataframe: DataFrame, features_columns):\n",
    "    assembler = VectorAssembler(inputCols=features_columns, outputCol='features')\n",
    "    return assembler.transform(dataframe)\n",
    "\n",
    "\n",
    "def scale_features(dataframe: DataFrame, with_mean=True, with_std=True):\n",
    "    scaler = StandardScaler(inputCol='features', outputCol='scaled_features', withMean=with_mean, withStd=with_std).fit(\n",
    "        dataframe)\n",
    "    return scaler.transform(dataframe)\n",
    "\n",
    "\n",
    "def corr_features(dataframe: DataFrame, method='pearson'):\n",
    "    return Correlation.corr(dataframe, \"features\", method=method).head()[0].toArray()\n",
    "\n",
    "\n",
    "def write_training_time(path:str, training_time):\n",
    "    with open(\"{}/training_time.txt\".format(path), 'w') as f:\n",
    "        f.write('{:.2f}'.format(training_time))\n",
    "\n",
    "\n",
    "def read_training_time(path:str):\n",
    "    with open(\"{}/training_time.txt\".format(path)) as f:\n",
    "        result = float(f.read())\n",
    "    return result\n",
    "\n",
    "\n",
    "def show_confusion_matrix(predictions: DataFrame, model_name: str):\n",
    "    metrics = MulticlassMetrics(predictions.select('prediction', 'label').rdd)\n",
    "    sns.heatmap(metrics.confusionMatrix().toArray(), annot=True)\n",
    "    plt.savefig('{}.png'.format(model_name))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def show_auc(predictions: DataFrame, model_name: str):\n",
    "    print(\"AUC for {}: {}\".format(model_name, BinaryClassificationEvaluator().evaluate(predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7f49f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_cancer_data = spark.read.options(header=True, inferSchema='True').csv(\"breast cancer.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fdf46bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessor:\n",
    "    def __init__(self, dataframe: DataFrame, true_condition, label_column: str, features_columns, normalize=True):\n",
    "        self.dataframe = assemble_features(dataframe, features_columns)\n",
    "        if normalize:\n",
    "            self.dataframe = scale_features(self.dataframe, True, True)\n",
    "        self.dataframe = self.dataframe.withColumn(\"label\", true_condition(col(label_column)))\n",
    "        features = col('scaled_features').alias('features') if normalize else col('features')\n",
    "        self.dataframe = self.dataframe.select(\"label\", features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5904f523",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(dataframe: DataFrame):\n",
    "    preprocessor = Preprocessor(dataframe, lambda d: (d == 'M').cast('float'), 'diagnosis', dataframe.columns[2:], True)\n",
    "    return preprocessor.dataframe\n",
    "\n",
    "\n",
    "def save_correlation_matrix(dataframe: DataFrame):\n",
    "    correlation_matrix = corr_features(dataframe)\n",
    "    sns.heatmap(correlation_matrix)\n",
    "    plt.savefig('correlation_matrix.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d05821a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_features:30\n"
     ]
    }
   ],
   "source": [
    "n_features = len(breast_cancer_data.columns[2:])\n",
    "print(\"n_features:{}\".format(n_features))\n",
    "df = preprocess_data(breast_cancer_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "088c5d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_model: PCAModel = PCA(k=n_features, inputCol='features', outputCol='pca_features').fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8b3fd275",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9864881227145469"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(pca_model.explainedVariance[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "95b0ecf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_train, df_test) = df.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "611c47c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegressionBuilder:\n",
    "    def __init__(self, training_df: DataFrame):\n",
    "        self.model_name = 'Logistic Regression'\n",
    "        if(isdir(self.model_name)):\n",
    "            self.model = LogisticRegressionModel.load(self.model_name)\n",
    "            self.training_time = read_training_time(self.model_name)\n",
    "        else:\n",
    "            lr = LogisticRegression(maxIter=100, regParam=0.3, elasticNetParam=0.8)\n",
    "            paramGrid = ParamGridBuilder() \\\n",
    "                        .addGrid(lr.regParam, [0.1,0.01,0.001]) \\\n",
    "                        .addGrid(lr.elasticNetParam, [0, 0.25, 0.5, 0.75, 1]) \\\n",
    "                        .build()\n",
    "            crossval = CrossValidator(estimator=lr,\n",
    "                              estimatorParamMaps=paramGrid,\n",
    "                              evaluator=BinaryClassificationEvaluator(),\n",
    "                              numFolds=3)\n",
    "            start = time.time()\n",
    "            self.model = crossval.fit(training_df).bestModel\n",
    "            self.training_time = time.time()-start\n",
    "            self.model.save(self.model_name)\n",
    "            write_training_time(self.model_name, self.training_time)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "2a761da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got best LR model in 66.7 seconds\n"
     ]
    }
   ],
   "source": [
    "lrb = LogisticRegressionBuilder(df_train)\n",
    "print(\"Got best LR model in {} seconds\".format(lrb.training_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "7e183566",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_predictions = lrb.model.transform(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "e5ee1566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC for RL_Model: 0.9979583503470805\n"
     ]
    }
   ],
   "source": [
    "show_auc(lr_predictions, lrb.model_name)\n",
    "show_confusion_matrix(lr_predictions, lrb.model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a2aee3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
